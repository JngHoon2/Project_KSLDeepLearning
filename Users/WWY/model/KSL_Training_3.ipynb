{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KSL_Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9tPfq7SwaOO"
      },
      "source": [
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORTly8jUwIx3",
        "outputId": "d4c3db07-85a1-4246-e89e-4fbc8fb600db"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tQG28xSeuc--",
        "outputId": "8b6e6124-4f65-40b4-c497-8c44bd6388e3"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/gdrive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUY-Dry7Bu5I"
      },
      "source": [
        "os.chdir(f'{os.getcwd()}\\\\Desktop\\\\colab_local')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG9bSyNzxbTt",
        "outputId": "2172f80e-2fc2-4cfc-e5ec-30d6cb59e93d"
      },
      "source": [
        "# 만약에 파일 없으면 !mkdir \"KSLProject\"\n",
        "\n",
        "%cd 'MyDrive'\n",
        "%cd 'KSLProject'\n",
        "# %cd 'hmdb51'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive\n",
            "/gdrive/MyDrive/KSLProject\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JGUP4CTzCgr",
        "outputId": "340f83b5-741d-4700-a813-2caf9f573e93"
      },
      "source": [
        "!wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-19 18:22:59--  http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
            "Resolving serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)... 128.148.254.114\n",
            "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar [following]\n",
            "--2021-05-19 18:22:59--  https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
            "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2124008126 (2.0G)\n",
            "Saving to: ‘hmdb51_org.rar’\n",
            "\n",
            "hmdb51_org.rar      100%[===================>]   1.98G  19.8MB/s    in 74s     \n",
            "\n",
            "2021-05-19 18:24:13 (27.4 MB/s) - ‘hmdb51_org.rar’ saved [2124008126/2124008126]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y97dkozn348n",
        "outputId": "c52925d0-aba5-4d83-efe0-9f2b58017ab2"
      },
      "source": [
        "# %cd \"../\"\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m문서\u001b[0m/  conv_lstm_2d.h5  \u001b[01;34mhmdb51\u001b[0m/  hmdb51_org.rar  model.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWbvLYqk39QA"
      },
      "source": [
        "#unzip rar file\n",
        "!unrar x ../hmdb51_org.rar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmT9xwcX0lv8"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyb2c_eD3CYU"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okwzROh049Oq"
      },
      "source": [
        "!unrar x for i in brush_hair.rar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdlCKIU76e54"
      },
      "source": [
        "file_list = []\n",
        "file_list = os.listdir(os.getcwd())\n",
        "print(file_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d00KNZJj7Xoq"
      },
      "source": [
        "cur_path = os.getcwd() \n",
        "cur_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK7AKAqJ65fY"
      },
      "source": [
        "# for x in file_list:\n",
        "#   !unrar x cur_path\n",
        "!unrar x for i in file_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TANcp2Y48Qmk"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJK2ZDVE8V7H"
      },
      "source": [
        "frames = 15\n",
        "Width = 256\n",
        "Height = 256"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETGyHzRW8f06"
      },
      "source": [
        "#비디오명과 레이블 짝을 가져온다.\n",
        "def load_video_names(path):\n",
        "\n",
        "  videos = []\n",
        "  labels = []\n",
        "  for category in os.listdir(path): #root 폴더의 각 하위폴더들은 클래스이름이기 때문에 이것을 category로 저장\n",
        "    for video in os.listdir(path+\"/\"+category): #인자로 받은 경로(path)와 클래스명을 붙여서 각각의 비디오별\n",
        "      videos.append(path+\"/\"+category+\"/\"+video) #비디오의 경로명을 videos에 넣는다.\n",
        "      labels.append(category) #category명 즉 폴더명이 클래스이므로 label로 넣는다.\n",
        "  return np.array(videos), np.array(labels) #이것들을 array값으로 반환한다.\n",
        "\n",
        "#프레임 전처리 함수 preprocess()\n",
        "def preprocess(frame):\n",
        "  frame = cv2.resize(frame, (Width, Height))\n",
        "  # 프레임 픽셀 -1에서 1 범위로 정규화(normalization)\n",
        "  frame = frame - 127.5 # RGB값 : 255/2 - 0.5\n",
        "  frame = frame / 127.5\n",
        "  return frame\n",
        "\n",
        "#비디오 불러오기 함수 load_video()\n",
        "def load_video(video_path):\n",
        "  video_frames = []\n",
        "  cap = cv2.VideoCapture(video_path) #비디오 경로를 입력하여 cap 인자로 cv2비디오캡처를 실행\n",
        "  while True:\n",
        "    ret, frame = cap.read() #비디오의 캡처를 읽어오고\n",
        "    if ret == True: #실행되는 동안\n",
        "      video_frames.append(preprocess(frame)) #전처리된 프레임을 video_frames 리스트에 추가\n",
        "    else:\n",
        "      break\n",
        "  cap.release()\n",
        "  video_frames = select_frames(video_frames) #비디오 프레임을 select frames()에 처리시킨다.\n",
        "  if len(video_frames) != frames:\n",
        "    print('short_video ',video_path, len(video_frames))\n",
        "    \n",
        "  return np.array(video_frames)\n",
        "\n",
        "\n",
        "def select_frames(video_frames): # video_frames인자는 전처리한 프레임들을 저장한 리스트 형태\n",
        "  selected_frames = []\n",
        "  if len(video_frames) > frames: # 전체 비디오 프레임 수가 지정한 프레임 (15)보다 큰 동안\n",
        "    fn = len(video_frames)//frames # 전체 프레임수를 지정프레임수로 나누고 나머지를 버린 몫을 fn으로 산정 ( //연산자 : 나눈 값에서 소수점을 버린 정수값을 취함)\n",
        "    # 예를들어 가져온 비디오의 전체프레임이 119프레임이라할때 15로 나누면 7.93333 이고 여기에 나머지를 버리면 7이라는 값이 나옴\n",
        "    # 즉, 전체프레임에서 fn만큼의 간격을 두고 15개의 프레임을 취하기 위해서 이 함수가 존재하는것\n",
        "    f_num = 0 # 현재 선택된 프레임의 수 \n",
        "    for f in video_frames: # 각각의 비디오 프레임 값(array배열 값)에 대해서 f로 지정\n",
        "      if len(selected_frames) < frames: # 만약 선택된 프레임의 수가 전체 할당하고자하는 프레임 수(15)보다 작은 상태라면\n",
        "        if f_num % fn == 0: # f_num이 fn의 배수가 될 때마다(나누어 떨어질 때마다) 해당 프레임의 위치를 표시\n",
        "          selected_frames.append(f) # selected_frames에 프레임을 추가\n",
        "          #즉 fn이 7값이면 7프레임 단위로 끊어서 전체 비디오의 프레임을 가져온다. 7 * 15 = 105, 7 * 16 = \n",
        "      f_num += 1 # 선택된 프레임 수 1 증가\n",
        "  else:\n",
        "    selected_frames = video_frames #만약 전체 비디오의 프레임 수가 지정한 프레임(15)보다 작은경우 그냥 그프레임 자체를 데이터로 설정\n",
        "  return selected_frames  #즉, 전체 프레임을 설정한 frames=15라는 값에 의해 15개의 프레임만 선택적으로 균일한 간격을 이루어 선택적으로 취하는 코드\n",
        "\n",
        "# X, y = create_dataset(videos, encoded_labels, selected_indexes)\n",
        "def create_dataset(videos, labels, indx):\n",
        "  \"\"\"\n",
        "  이 함수는 배치사이즈 크기만큼의 비디오를 불러오는 데 사용. load_video로 우선 단일 비디오를 불러오는 것을 매개로 함\n",
        "  파라미터\n",
        "  videos : 모든 비디오의 경로값\n",
        "  labels : 비디오들의 아웃풋 클래스\n",
        "  indx : 배치로 사용되는 비디오들의 인덱스\n",
        "  \"\"\"\n",
        "  X = []\n",
        "  y = []\n",
        "  for video, label in zip(videos[indx], labels[indx]):\n",
        "    X.append(load_video(video))\n",
        "    y.append(label)\n",
        "\n",
        "  return np.array(X), np.array(y)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_wU1ALQ_grD"
      },
      "source": [
        "videos, labels = load_video_names('./temp_data') #path ./hmdb51 내에 있는 각각의 클래스 폴더들의 비디오 이름들을 가져와 videos와 labels로 할당한다.\n",
        "samples = len(videos)\n",
        "# videos[0][-3:]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYRYASi2EnGE",
        "outputId": "e4c16216-6ca3-44dc-8d00-4955760831bc"
      },
      "source": [
        "samples\n",
        "# print(labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7GrM53q_zl-"
      },
      "source": [
        "#모든 비디오의 label값이 중복으로 나타나는 것을\n",
        "#np.unique()함수를 이용하여 같은값의 중복을 없앰\n",
        "classes = len(np.unique(labels)) \n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaOoVRvr_3Dt",
        "outputId": "95e51d37-d056-46e7-fd65-25b014bbabd1"
      },
      "source": [
        "classes"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhgQ03VU_6Vl"
      },
      "source": [
        "# print(np.unique(labels, return_counts=True))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcA-BUl-E_tL",
        "outputId": "f863a84e-aea9-4ce2-d1bc-3e75e5a0f483"
      },
      "source": [
        "#비디오가 제대로 불러와졌는지 확인\n",
        "\n",
        "labels_counts = np.unique(labels, return_counts=True) #각 레이블이 몇 개씩 존재하는지 반환하는 인자 return_counts\n",
        "print(labels_counts)\n",
        "print(np.shape(labels_counts))\n",
        "for l, n in zip(labels_counts[0], labels_counts[1]): #l과 n에 각각 첫번째 배열의 요소와 두번째 배열의 요소를 대응\n",
        "# l값은 분류 레이블의 이름이 저장되어있고 n값은 해당 레이블의 개수가 저장되어있음\n",
        " print(l,n)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array(['등', '무릎', '발', '발가락', '발목', '발작', '복부'],\n",
            "      dtype='<U8'), array([20, 20, 20, 20, 20, 20, 20]))\n",
            "(2, 7)\n",
            "등 20\n",
            "무릎 20\n",
            "발 20\n",
            "발가락 20\n",
            "발목 20\n",
            "발작 20\n",
            "복부 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDXKUOu3FRxR",
        "outputId": "95bc4887-411c-4d8a-9094-31efbd3f0259"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "le = LabelEncoder() #LabelEncoder() 객체를 통해 문자로 이루어진 클래스를 숫자 형태로 적용\n",
        "le.fit(np.unique(labels)) #label의 유니크 값을 le.fit()함수에 넣어 고유값을 fitting 시킴\n",
        "\n",
        "encoded_labels = le.transform(labels) #fit을 시켜주지 않으면 다음과 같은 에러메세지를 출력 \n",
        "# This LabelEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n",
        "# print(encoded_labels) # 결과값 : [63 63 63 ... 2  2  2]\n",
        "encoded_labels = np.reshape(encoded_labels, (-1,1)) # 하나의 row에 값들을 나열 (수평축의 크기를 1로 해서 1개의 요소가 들어가면 다음 열로 넘어감)\n",
        "# print(encoded_labels)\n",
        "\n",
        "encoder = OneHotEncoder()\n",
        "encoder.fit(encoded_labels) # 나열된 레이블 값들을 원핫 인코더에 적용시키기 위해 .fit()실행\n",
        "encoded_labels = encoder.transform(encoded_labels)\n",
        "\n",
        "print(encoded_labels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 2)\t1.0\n",
            "  (1, 2)\t1.0\n",
            "  (2, 2)\t1.0\n",
            "  (3, 2)\t1.0\n",
            "  (4, 2)\t1.0\n",
            "  (5, 2)\t1.0\n",
            "  (6, 2)\t1.0\n",
            "  (7, 2)\t1.0\n",
            "  (8, 2)\t1.0\n",
            "  (9, 2)\t1.0\n",
            "  (10, 2)\t1.0\n",
            "  (11, 2)\t1.0\n",
            "  (12, 2)\t1.0\n",
            "  (13, 2)\t1.0\n",
            "  (14, 2)\t1.0\n",
            "  (15, 2)\t1.0\n",
            "  (16, 2)\t1.0\n",
            "  (17, 2)\t1.0\n",
            "  (18, 2)\t1.0\n",
            "  (19, 2)\t1.0\n",
            "  (20, 3)\t1.0\n",
            "  (21, 3)\t1.0\n",
            "  (22, 3)\t1.0\n",
            "  (23, 3)\t1.0\n",
            "  (24, 3)\t1.0\n",
            "  :\t:\n",
            "  (115, 0)\t1.0\n",
            "  (116, 0)\t1.0\n",
            "  (117, 0)\t1.0\n",
            "  (118, 0)\t1.0\n",
            "  (119, 0)\t1.0\n",
            "  (120, 1)\t1.0\n",
            "  (121, 1)\t1.0\n",
            "  (122, 1)\t1.0\n",
            "  (123, 1)\t1.0\n",
            "  (124, 1)\t1.0\n",
            "  (125, 1)\t1.0\n",
            "  (126, 1)\t1.0\n",
            "  (127, 1)\t1.0\n",
            "  (128, 1)\t1.0\n",
            "  (129, 1)\t1.0\n",
            "  (130, 1)\t1.0\n",
            "  (131, 1)\t1.0\n",
            "  (132, 1)\t1.0\n",
            "  (133, 1)\t1.0\n",
            "  (134, 1)\t1.0\n",
            "  (135, 1)\t1.0\n",
            "  (136, 1)\t1.0\n",
            "  (137, 1)\t1.0\n",
            "  (138, 1)\t1.0\n",
            "  (139, 1)\t1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmRhB0RRFubo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a4a8990-1352-47a1-d145-e5e16b1715c1"
      },
      "source": [
        "# 인코딩 레이블 값을 array값으로 covert\n",
        "encoded_labels = encoded_labels.toarray()\n",
        "print(encoded_labels)\n",
        "#어쨋든 데이터로 들어가야 하는 레이블 값은 다음과 같은 값이어야 함"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59pOqgEcLZXA",
        "outputId": "cffca2e6-6a68-41ae-999c-4ba88f518753"
      },
      "source": [
        "np.shape(encoded_labels) #(영상 개수, 클래스 개수)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AkIMquJuzSm"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "seed = 0\n",
        "X_train , X_test, Y_train, Y_test = train_test_split(videos, encoded_labels, test_size=0.3, random_state=seed)\n",
        "\n",
        "train_samples = len(X_train)\n",
        "test_samples = len(X_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmsQ_CpsvTMn",
        "outputId": "3a748aaf-6203-48fb-af44-ca4ab9948e20"
      },
      "source": [
        "print(\"원본 동영상 X : \", np.shape(videos))\n",
        "print(\"훈련 동영상 X_train : {0}, 테스트 동영상 X_test: {1}\" .format(np.shape(X_train), np.shape(X_test)))\n",
        "\n",
        "print(\"원본 레이블 Y : \", np.shape(encoded_labels))\n",
        "print(\"훈련 레이블 Y_train : {0}, 테스트 레이블 Y_test : {1}\" .format(np.shape(Y_train), np.shape(Y_test)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원본 동영상 X :  (140,)\n",
            "훈련 동영상 X_train : (98,), 테스트 동영상 X_test: (42,)\n",
            "원본 레이블 Y :  (140, 7)\n",
            "훈련 레이블 Y_train : (98, 7), 테스트 레이블 Y_test : (42, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh3NKLlUF3PF"
      },
      "source": [
        "#케라스 모델 생성\n",
        "from keras.models import Input, Model\n",
        "from keras.layers import TimeDistributed, LSTM\n",
        "from keras.layers import ConvLSTM2D\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, LeakyReLU, BatchNormalization\n",
        "from keras.layers import Dense, Flatten, GlobalMaxPooling2D\n",
        "from keras.layers import MaxPooling3D\n",
        "from keras.layers import concatenate\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMQjyNHeL4mp"
      },
      "source": [
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKH3MAhWCPcP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_WsUw80zEUCY",
        "outputId": "02073429-2807-4ba6-b6da-42e16af0d0de"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC4YSY0uGcC1"
      },
      "source": [
        "'''\n",
        "feature extraction을 하기위해 사용하는 residual block\n",
        "한개의 CNN 레이어와 leaky relu가 action을 파악하는 펑션으로 포함되어있음\n",
        "'''\n",
        "def res_block(model, filters):\n",
        "  '''\n",
        "  feature extraction 하기 위한 residual block\n",
        "  1개의 CNN 레이어와 leaky relu action 함수 포함\n",
        "  '''\n",
        "\n",
        "  #model = TimeDistributed(Conv2D(filters=filters,\n",
        "  #kernel_size=3, padding='same'))(model)\n",
        "  start_block = model\n",
        "  model = Conv2D(filters=filters, kernel_size=3, padding='same')(model)\n",
        "  model = BatchNormalization(momentum=0.9)(model)\n",
        "  model = LeakyReLU(0.2)(model)\n",
        "  return concatenate([start_block, model])\n",
        "\n",
        "def create_model():\n",
        "  '''\n",
        "  전체 모델 구조를 설정, ConvLSTM2D 레이어를 구성\n",
        "  이를 통해 비디오의 spatial(공간적)특성과 temporal(일시성, 시간성)특성을 캐치\n",
        "\n",
        "  '''\n",
        "  input_layer = Input(shape=(frames, Width,Height,3))\n",
        "\n",
        "  model = ConvLSTM2D(32, 3 , padding='same', return_sequences=False)(input_layer)\n",
        "  model = BatchNormalization(momentum=0.9)(model)\n",
        "  model = LeakyReLU(0.2)(model)\n",
        "\n",
        "  filters = 64 #필터 개수 설정\n",
        "\n",
        "  for _ in range(6):\n",
        "    model = res_block(model, filters)\n",
        "    try:\n",
        "      model = MaxPooling3D((2,2,2))(model)\n",
        "    except:\n",
        "      model = MaxPooling2D((2,2))(model)\n",
        "    if filters < 512:\n",
        "      filters *= 2\n",
        "\n",
        "  #model = TimeDistributed(Conv2D(filters, 3 , padding='same'))(model)\n",
        "  #model = TimeDistributed(GlobalMaxPooling2D())(model)\n",
        "  model = Flatten()(model)\n",
        "\n",
        "  # 출력층\n",
        "  model = Dense(classes, activation='softmax')(model)\n",
        "  model = Model(input_layer , model)\n",
        "  model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pma6KdknIbKA"
      },
      "source": [
        "classifier = create_model()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wawRWRuHIeP4",
        "outputId": "c8509820-1089-402b-a36c-83f8fbd22406"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 15, 256, 256 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_lst_m2d (ConvLSTM2D)       (None, 256, 256, 32) 40448       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 256, 256, 32) 128         conv_lst_m2d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 256, 256, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 256, 256, 64) 18496       leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 256, 256, 64) 256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 256, 256, 64) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256, 256, 96) 0           leaky_re_lu[0][0]                \n",
            "                                                                 leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 128, 128, 96) 0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 128, 128, 128 110720      max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 128, 128, 128 512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 128, 128, 128 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 128, 128, 224 0           max_pooling2d[0][0]              \n",
            "                                                                 leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 224)  0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 64, 256)  516352      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64, 64, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 64, 64, 256)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 64, 64, 480)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 480)  0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 512)  2212352     max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 512)  2048        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 32, 32, 512)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 992)  0           max_pooling2d_2[0][0]            \n",
            "                                                                 leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 992)  0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 16, 16, 512)  4571648     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 512)  2048        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 16, 16, 512)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 16, 16, 1504) 0           max_pooling2d_3[0][0]            \n",
            "                                                                 leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 1504)   0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 8, 8, 512)    6930944     max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 8, 8, 512)    2048        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, 8, 8, 512)    0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 8, 8, 2016)   0           max_pooling2d_4[0][0]            \n",
            "                                                                 leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 2016)   0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 32256)        0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 7)            225799      flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 14,634,823\n",
            "Trainable params: 14,630,791\n",
            "Non-trainable params: 4,032\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFaJdlHqIhjo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "c4bcde06-c701-4a73-b8a6-3af1e66b1d98"
      },
      "source": [
        "# 모델 그래프 생성\n",
        "from keras.utils import plot_model\n",
        "plot_model(classifier)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-ea683552f45f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델 그래프 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_model' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bcsx10UbI24Z"
      },
      "source": [
        "#모델 저장할 경로 설정\n",
        "model_name = './conv_lstm_2d.h5'"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgs2d9rYI9oE"
      },
      "source": [
        "# pre-train된 가중치를 불러오기\n",
        "try:\n",
        "  classifier.load_weights(model_name)\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5wpKEFf-Cq8"
      },
      "source": [
        "def set_batches(samples, batch_size=4):\n",
        "  batch_size = batch_size\n",
        "\n",
        "  if samples//batch_size < samples/batch_size: #소수점 버리고 +1 \n",
        "    batches = (samples//batch_size)+1 #train_samples 기준 총 배치사이즈 : 888/4 = 222\n",
        "  else: # 소수점 없이 나누어 떨어지는 경우\n",
        "    batches = samples//batch_size \n",
        "\n",
        "  return batches"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbfPCGPBJKH0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8cab4aa1-6d9b-42a3-8e89-1f0f201c59f3"
      },
      "source": [
        "batch_size = 4 #batch 사이즈 설정\n",
        "# # total batches\n",
        "# # 기존 samples를 train_samples로 교체\n",
        "\n",
        "# # samples//batch_size = 1289 // 4  = 322 < 1289/4 = 322.25  9\n",
        "# if train_samples//batch_size < train_samples/batch_size: # \n",
        "#   batches = (train_samples//batch_size)+1 #train_samples 기준 총 배치사이즈 : 888/4 = 222\n",
        "# else:\n",
        "#   batches = train_samples//batch_size \n",
        "\n",
        "#model.fit() 대신에 train_on_batch()를 사용\n",
        "# 장점\n",
        "# 특정 주기에만 가중치를 업데이트 , 가중치 업데이트로 인한 학습시간을 단축할 수 있다.\n",
        "# 실시간 batch의 추적을 통해서 중간 저장이 가능하다.\n",
        "# 또한 각 배치 사이에서 값의 조정이 가능하다.\n",
        " \n",
        "# X_eval = []\n",
        "# Y_eval = []\n",
        "\n",
        "\n",
        "\n",
        "for e in range(100): #에폭 수 \n",
        "  score = []\n",
        "  test_accuracy = 0\n",
        "  # index = list(range(samples))\n",
        "  index = list(range(train_samples))                                                  ####################### 수정한 부분\n",
        "  np.random.shuffle(index) # 인덱스를 저장한 배열을 무작위 순서로 설정\n",
        "  accuracy = 0\n",
        "  \n",
        "  batches_for_train = set_batches(train_samples, batch_size)                                                              ###################### 2차 수정\n",
        "\n",
        "  for batch in range(batches_for_train): # 0 ~ 222\n",
        "    bs = batch*batch_size # MINIMUM = 0 * 4 = 0 ~ MAXIMUM = (222) * 4 =  # 0 ~ 888\n",
        "    be = bs+batch_size # MIN = 0 + 4 = 4 ~ MAX = 888 + 4 = 892\n",
        "    selected_indexes = index[bs:be] #index [0:888, 4:892]\n",
        "\n",
        "    # X, y = create_dataset(videos, encoded_labels, selected_indexes) \n",
        "    # 기존의 위 코드에서 train / test로 분리시켰기 때문에 videos, encoded_labels 대신에 X_train, Y_train 값을 부여\n",
        "    X, y = create_dataset(X_train, Y_train, selected_indexes)\n",
        "    \n",
        "    results = classifier.train_on_batch(X,y)\n",
        "    print('\\r', batch, '/', batches_for_train, ' : ', results[0], results[1], end='')\n",
        "    accuracy += results[1]\n",
        "    if batch%15 == 0:\n",
        "      classifier.save_weights(model_name)\n",
        "\n",
        "  print('\\r> ',e,', Train Accuracy = ', accuracy/batches_for_train)\n",
        "\n",
        "  index2 = list(range(test_samples))\n",
        "  np.random.shuffle(index2)\n",
        "  batches_for_test = set_batches(test_samples, batch_size) # = 11\n",
        "  for batch in range(batches_for_test):\n",
        "    bs = batches_for_test*batch_size #11 *4 = 44\n",
        "    be = bs+batch_size\n",
        "    selected_indexes2 = index2[bs:be]\n",
        "    X_test, Y_test = create_dataset(X_test, Y_test, selected_indexes2)\n",
        "    test_results = classifier.evaluate(X_test, Y_test, batch_size = batch_size, verbose=0) # [0] loss [1] accuracy\n",
        "    print(test_results)\n",
        "    # test_accuracy += test_results[1]\n",
        "\n",
        "  print(\"\\n Test Accuracy :\", test_accuracy/batches_for_test) # 정확성 평가 부분을 추가 ######################### 수정한 부분\n",
        "  classifier.save_weights(model_name)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">  0 , Train Accuracy =  0.99\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "\n",
            " Test Accuracy : 0.0\n",
            ">  1 , Train Accuracy =  0.95\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "\n",
            " Test Accuracy : 0.0\n",
            ">  2 , Train Accuracy =  0.98\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "\n",
            " Test Accuracy : 0.0\n",
            ">  3 , Train Accuracy =  0.97\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "\n",
            " Test Accuracy : 0.0\n",
            ">  4 , Train Accuracy =  0.97\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "\n",
            " Test Accuracy : 0.0\n",
            " 14 / 25  :  9.040936856763437e-05 1.0"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-4ea4abe69183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# X, y = create_dataset(videos, encoded_labels, selected_indexes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# 기존의 위 코드에서 train / test로 분리시켰기 때문에 videos, encoded_labels 대신에 X_train, Y_train 값을 부여\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_indexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-274bb8ca4025>\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(videos, labels, indx)\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-274bb8ca4025>\u001b[0m in \u001b[0;36mload_video\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#비디오의 캡처를 읽어오고\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#실행되는 동안\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0mvideo_frames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#전처리된 프레임을 video_frames 리스트에 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-274bb8ca4025>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#프레임 전처리 함수 preprocess()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mWidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0;31m# 프레임 픽셀 -1에서 1 범위로 정규화(normalization)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m127.5\u001b[0m \u001b[0;31m# RGB값 : 255/2 - 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}